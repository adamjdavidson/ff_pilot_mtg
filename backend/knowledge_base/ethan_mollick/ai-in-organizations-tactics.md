# AI in organizations: Some tactics

Source: [One Useful Thing Newsletter](https://www.oneusefulthing.org/p/ai-in-organizations-some-tactics)
Date: October 4, 2024
Tags: AI, organizations, tactics, productivity, implementation, strategy

I've been thinking a lot about how organizations adapt to AI, and I want to share some of my observations and suggestions.

## The current state of AI adoption

First, the data is pretty clear – AI is being widely adopted in the workplace. Two Danish surveys found 65% of marketers and 64% of journalists had used AI at work. A representative survey of American workers conducted by Microsoft showed a third had used Generative AI in the past week. The same Microsoft survey also offered insights into which tools people are using: ChatGPT dominates, followed by Google's Gemini.

The data on productivity is also pretty convincing. The use of large language models by consultants, using GPT-4, have shown a 25% improvement in speed with comparable or better quality. GitHub Copilot data suggests a 26% gain in productivity among coders. In the one publicly-available user experience study I know of, from Microsoft, when people estimated the impact of AI on their work, they reported that AI cut their working time by half on 41% of tasks.

The problem facing firms is not getting people to use AI (though there are some important issues around trust and fear). The problem is not whether AI improves individual productivity. The problem is turning individual productivity gains into organizational productivity gains, and how to adapt organizations to a rapidly changing technological environment.

## The discovery gap

AI is weird. The biggest companies in the world are releasing models that have massive capabilities, but aren't sure how these models should be used. For example, GPT-4 was released with the equivalent of a brief user manual. It told you what it was good for, but those claims were based on statistics relevant to overall capability, not specific tasks. AI companies essentially released the models without really knowing their best use cases, though they have since done a lot of internal research on that subject. There is no definitive guide to what AI can do for your firm, how to use AI more effectively, what the overall strategies for AI should be for a company.

This means that any organization that wants to use AI effectively is, to a large extent, on their own. They need to develop their own playbook. And, since we still don't know all the capabilities and optimal approaches to using these tools, they need to be engaged in discovery – essentially a form of applied research. This is where I observe firms are underinvesting in understanding AI, as opposed to buying licenses and signing people up. And, more importantly, there does not seem to be a consensus approach for how to help with discovery.

## Some approaches to using AI better in firms

Based on my observations, conversations with executives, and my own research, I see a few approaches to using AI better in organizations, though the ideal is some mix of tactics. Here are some possible approaches.

### Approach 1: The Crowd

The crowd approach is based on a de-centralized approach to innovation, and assumes that, since AI is a tool for enhancing individual productivity, most of the innovation in how it should be used will emerge organically from the crowd. This approach also has the benefit of maximizing current individual productivity gains, even at the risk of losing some organizational learning.

Under this model, firms try to reduce employee fear about AI. This may involve clear guidelines on how the AI should be used ethically (you can see examples of my own research-backed guidelines in an article I wrote for Harvard Business Review), guarantees of no layoffs due to AI productivity increases, and the provision of subscriptions to top AI tools.

Under this model, firms may also establish incentives for reporting successful AI approaches to leadership or creating gatherings for exchanging knowledge and prompt strategies. However, there's an important consideration to keep in mind — these strategies need to be backed by psychological safety. Employees are often hesitant to use AI or to report their successful use cases out of concerns that doing so might lead to job loss or other future problems.

### Approach 2: The Lab

The Lab approach is a more centralized approach, where firms dedicate resources to research-oriented activities aimed at discovering better ways to use AI in the organization. This is a distinct role from IT, though IT should be involved. Its more like product development or user experience combined with benchmarking.

Under this approach, companies run actual trials and productivity tests (I know more than one company that has their own prompt-off competition to see which approach to AI works best), benchmark capabilities, build expert understanding of AI capabilities and how they can be used within the firm, and create custom prompts and tools. 

Some companies go even farther, setting up AI agents to see how they could automate aspects of communication, creating "provocations and magic" (to borrow a phrase from a firm I spoke with that does this) to demo to employees what AI can do. The lab staff serves as resident experts in how to use AI well within an organization, and can disseminate this knowledge to others.

This approach is most useful for firms whose work requires a deep approach to using AI capability. For example, I know two large law firms doing something like this, and they have found that by studying how to use AI well for legal purposes, they can create prompts that save huge amounts of time while producing high-quality, reliable legal work.

## Need for research

While I've been thinking about these issues for some time, they remain what I would describe as a sketch of a framework. What's the tradeoff between decentralized approaches to AI (maximizing current productivity but potentially missing organizational learning) and centralized (potentially improving organizational approaches, but not maximizing short term productivity)? We don't know. Different industries likely need different approaches to AI adoption; what are those differences? There are organizational design implications to how AI is introduced to a firm; what are they? How do we manage the transition from individually-valuable AI to team-based approaches to using it? And I'm just getting started.

The issue is that any approach to thinking about how to use AI in a firm is, to a large degree, a form of research under conditions of uncertainty. Firms really are on their own, and given the productivity gains from AI, are still essentially conducting their own experiments, while doing little in the way of research on the best ways to use the technology. Here, I think academia can help, by studying what firms are doing, even if we have no definitive answers as of yet. Solving these issues will be key to unlocking the real productivity potential of AI, and allowing the transformation from individual benefit to organizational benefits.