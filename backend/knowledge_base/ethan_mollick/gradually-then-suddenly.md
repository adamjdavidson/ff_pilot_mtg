# Gradually, then Suddenly: Upon the Threshold

Source: [One Useful Thing Newsletter](https://www.oneusefulthing.org/p/gradually-then-suddenly-upon-the)
Date: July 4, 2024
Tags: AI, technological thresholds, adoption, AI capabilities, image generation, video generation, transcription

Ernest Hemingway has a famous line in The Sun Also Rises when a character is asked how he went bankrupt. "Two ways," he answers. "Gradually, then suddenly." The same is true of technological change. Often, a technology gets incrementally better over time, crossing various thresholds of capability, until it suddenly becomes useful in new ways. We see the implications of a gradually-evolving technology in sudden bursts, as it crosses thresholds we care about. And if there is one thing that is true about AI, it is that it is rapidly crossing thresholds of capability at an incredible rate.

## Technology thresholds

Let me give you an example of a threshold. When digital cameras were first introduced, they were expensive and produced very low-quality pictures. Over time, the sensors in digital cameras gradually improved, with higher resolution and better low-light capabilities. But there was a magic moment: when digital cameras crossed the threshold of Polaroid-level quality, they became dramatically more useful. The image wasn't that great from a digital camera that matched a Polaroid camera, but it was good enough for many use cases, and had unique advantages: you got the pictures immediately, could send them by email, didn't have to buy film, etc. So, at that threshold, digital camera sales skyrocketed, and Polaroid filed for bankruptcy.

This kind of threshold is critical, because that is when a technology becomes useful for a dramatically expanded set of applications. Crossing these kinds of thresholds creates sudden change, even if the underlying technology is gradually improving. (I wrote an HBR article on this topic if you are interested in more about the role of thresholds in determining when technology becomes useful).

## Crossing thresholds

I am writing this because I think AI is crossing thresholds of capability on multiple fronts. If you have been keeping up, the improvements may seem gradual, but sudden improvements in capability are happening all over AI. Let me give a few recent examples.

### AI Images

DALL-E 3 represented a threshold of capability for AI-created images (Midjourney is also at a similar threshold). Look at how rapidly images improved over time:

DALL-E 1, April 2022: Competent, but not especially realistic or detailed. [Image shows a horse standing in front of a house]

DALL-E 2, April 2022: Much improved, but still very noticeable artifacts. [Image shows a horse with some artifacts]

DALL-E 3, September 2023: At a threshold of photorealism for many cases. [Image shows a highly realistic horse]

DALL-E 3, in combination with other tools like ControlNet, can do things that would have been impossible a few versions ago, like automatically colorizing this 1946 picture of my grandfather when he was a graduate student. The picture isn't perfect, but, once again, represents a threshold of capability: it does a good enough job, automatically, in a way that is extremely efficient.

### AI Video

AI video is also getting increasingly capable. What is striking is how dramatically faster the AI video models have improved compared to images. It took decades for computer graphics to reach convincing animation, but the jump from the original DALL-E models (which couldn't do video at all) to fairly convincing video output took less than two years.

Look at the improvement in AI-generated videos from just a single company, Runway, over just a few months:

Gen 1, May 2023: Very simple, brief video clips of 24 frames. Barely useful for anything beyond brief motion.

Gen 2, November 2023: Dramatic improvements, but still lots of artifacts. Useful for creating short videos, especially with careful prompt crafting and many iterations.

Gen 3, June 2024: Dramatic improvements again, with much more realistic looking imagery. Moving closer to the threshold of looking like amateur videos.

This is rapid improvement, and some of these videos are crossing the threshold of useful for a surprising number of applications. I've started to use Runway for creating video animations of characters and objects in case studies.

### AI Transcription and data processing

I've been genuinely shocked at how rapidly multi-modal AI systems have improved at the task of dealing with everything from text to video to audio. For example, check out this audio task which was simply impossible for AI systems until very recently.

I asked both GPT-4o and Claude 3.5 (the current best systems from OpenAI and Anthropic) to help me analyze data from a conversation I had with a business owner. I gave them a recording from a podcast, asked them to transcribe it, and then help me extract data from the audio recording. The specific task I asked them to do was to find when in the conversation specific topics were discussed.

Both systems did an amazing job with this task, though there were some minor differences in output. Here is Claude's response, which I loved:

[Transcription details and timestamp summary shown in the image]

The fact that AI can now help with complex audio processing in this way represents a massive threshold of capability for using AI in business. Being able to transcribe conversations is an enormous time savings, but being able to automatically extract insights from those conversations represents a step change in capability.

### Claude Artifacts: AI Assistants reach a new threshold

I also want to highlight one more multi-modal advancement that has crossed a threshold: Claude Artifacts. With Claude 3.5 Sonnet, Claude can now create useful mini-applications directly within the chat interface. For example, I can ask Claude to "create a supply and demand model where I can adjust the parameters and see the outputs."

Claude creates an interactive supply and demand economic model with sliders and a graph, all directly within the chat. I can then adjust sliders for supply elasticity, demand elasticity, equilibrium price, and equilibrium quantity - and the graph updates in real time.

This might not seem like much, but I assure you that it represents an enormously useful threshold in capability. I am starting to use this for teaching, but also for my own learning and exploration.

I am just showing a few examples here, but I have been testing all sorts of applications and seeing thresholds being crossed. I've started keeping an "impossibility list" of things that AI supposedly can't do, or at least doesn't do very well. I test these things regularly with the newest models to see what is now possible.

The pattern I am seeing is that the lines on my impossibility list are getting crossed faster and faster. Things that were considered major limitations of AI models a year ago are now capabilities that work fairly well. This has major implications for what AI can do â€“ and for the future.

I haven't talked about implications, or risks, or opportunities here. I am not making predictions. I'm just noting that thresholds of capability are being crossed faster than most people realize. People who want to use AI most effectively should be checking their own impossibility lists regularly to see what is now possible.